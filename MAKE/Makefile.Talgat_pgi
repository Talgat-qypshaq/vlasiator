CMP = mpic++
LNK = mpic++
NVCC = nvcc

# Suggested modules for building with PG19.7:
# module load pgi hpcx-mpi/2.5.0-cuda cuda
#
# Suggested modules for building with PGI20.9:
# module purge
# module unuse /appl/spack/modulefiles/linux-rhel7-x86_64/Core
# module use /appl/test/new_pgi/modulefiles/linux-rhel7-x86_64/Core/
# module load pgi cuda openmpi papi

#======== Vectorization ==========
#Set vector backend type for vlasov solvers, sets precision and length.
#Options:
# AVX:	    VEC4D_AGNER, VEC4F_AGNER, VEC8F_AGNER
# AVX512:   VEC8D_AGNER, VEC16F_AGNER
# Fallback: VEC4D_FALLBACK, VEC4F_FALLBACK, VEC8F_FALLBACK

ifeq ($(DISTRIBUTION_FP_PRECISION),SPF)
#Single-precision
	#VECTORCLASS = VEC8F_FALLBACK
	INC_VECTORCLASS = -Ivlasovsolver/vectorclass_fallback.h
	VECTORCLASS = VEC_FALLBACK_GENERIC
	COMPFLAGS += -DVECL=8 -DVEC_PER_PLANE=2 -DVEC_PER_BLOCK=8 -DVPREC=4
else
#Double-precision
	#VECTORCLASS = VEC4D_FALLBACK
	INC_VECTORCLASS = -Ivlasovsolver/vectorclass_fallback.h
	VECTORCLASS = VEC_FALLBACK_GENERIC
	COMPFLAGS += -DVECL=4 -DVEC_PER_PLANE=4 -DVEC_PER_BLOCK=16 -DVPREC=8
endif

#======== PAPI ==========
#Add PAPI_MEM define to use papi to report memory consumption?
#CXXFLAGS += -DPAPI_MEM
#testpackage: CXXFLAGS += -DPAPI_MEM

#======== Allocator =========
#Use jemalloc instead of system malloc to reduce memory fragmentation https://github.com/jemalloc/jemalloc
#Configure jemalloc with  --with-jemalloc-prefix=je_ when installing it
#CXXFLAGS += -DUSE_JEMALLOC -DJEMALLOC_NO_DEMANGLE


#======= Compiler and compilation flags =========
# NOTES on compiler flags:
# CXXFLAGS is for compiler flags, they are always used
# MATHFLAGS are for special math etc. flags, these are only applied on solver functions
# LDFLAGS flags for linker

#-DNO_WRITE_AT_ALL:  Define to disable write at all to
#                    avoid memleak (much slower IO)
#-DMPICH_IGNORE_CXX_SEEK: Ignores some multiple definition
#                         errors that come up when using
#                         mpi.h in c++ on Cray

#FLAGS =
CC = g++
NVCC = nvcc
CUDAFLAGS += -arch=sm_60

#GNU flags:
CC_BRAND = pgi
CC_BRAND_VERSION = 19.7
CXXFLAGS += -g -O2 -D__GCC_ATOMIC_TEST_AND_SET_TRUEVAL=1 -Minfo=accel -ta=tesla:lineinfo,keepbin,keepgpu,keepptx -Manno -g -nomp
#testpackage: CXXFLAGS = -g -O2 -acc -D__GCC_ATOMIC_TEST_AND_SET_TRUEVAL=1 -Minfo=accel
testpackage: CXXFLAGS += -g -O2 -D__GCC_ATOMIC_TEST_AND_SET_TRUEVAL=1 -Minfo=accel -ta=tesla:lineinfo,keepbin,keepgpu,keepptx -Manno -nomp

CUDAFLAGS += -D${FP_PRECISION}
CUDAFLAGS += -D${DISTRIBUTION_FP_PRECISION}

MATHFLAGS =
LDFLAGS = -O2 -g  -ta=tesla:lineinfo,keepbin,keepgpu,keepptx
LIB_MPI =

# BOOST_VERSION = current trilinos version
# ZOLTAN_VERSION = current trilinos verson

#======== Libraries ===========

MPT_VERSION = 7.5.1
JEMALLOC_VERSION = 4.0.4
LIBRARY_PREFIX = /home/mangla/libs

#compiled libraries
INC_BOOST = -I/usr/include/boost/
LIB_BOOST = -L/usr/lib/x86_64-linux-gnu/ -lboost_program_options

#INC_BOOST = -I/$(LIBRARY_PREFIX)/boost
#LIB_BOOST = -L/$(LIBRARY_PREFIX)/trilinos -lboost_program_options

INC_ZOLTAN = -I/$(LIBRARY_PREFIX)/include
LIB_ZOLTAN = -L/$(LIBRARY_PREFIX)/lib -lzoltan

INC_JEMALLOC = -I/$(LIBRARY_PREFIX)/include
LIB_JEMALLOC = -L/$(LIBRARY_PREFIX)/lib -ljemalloc -Wl,-rpath=$(LIBRARY_PREFIX)/lib

INC_VLSV = -I$(LIBRARY_PREFIX)/vlsv
LIB_VLSV = -L$(LIBRARY_PREFIX)/vlsv -lvlsv -Wl,-rpath=$(LIBRARY_PREFIX)/vlsv/lib

LIB_PROFILE = -L$(LIBRARY_PREFIX)/phiprof/lib -lphiprof -Wl,-rpath=$(LIBRARY_PREFIX)/phiprof/lib
INC_PROFILE = -I$(LIBRARY_PREFIX)/phiprof/include

LIB_CUDA = -L/usr/local/cuda/lib64 -lcuda -lcudart


#header libraries
INC_EIGEN = -I$(LIBRARY_PREFIX)/eigen
INC_DCCRG = -I$(LIBRARY_PREFIX)/dccrg
INC_FSGRID = -I$(LIBRARY_PREFIX)/fsgrid
